{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tshepo/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:49: FutureWarning:\n",
      "\n",
      "The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scipy\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "import warnings\n",
    "# String styling\n",
    "class color:\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Preparation: Data Cleaning, Relabeling, Wrangling and splitting subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File dataset/salary.csv does not exist: 'dataset/salary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d79eb0905d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fill Nan values is salary column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_salary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/salary.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_salary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_salary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_salary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Rename as per metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File dataset/salary.csv does not exist: 'dataset/salary.csv'"
     ]
    }
   ],
   "source": [
    "#Fill Nan values is salary column\n",
    "df_salary = pd.read_csv('dataset/salary.csv')\n",
    "df_salary = df_salary.fillna(df_salary.salary.mean())\n",
    "\n",
    "#Rename as per metadata\n",
    "df_salary =df_salary.rename(columns ={'male':'gender', 'experior':'Experience', 'yearsabs':'years_absent'})\n",
    "df_salary.gender = ['male' if i == 1 else 'female' for i in df_salary.gender]\n",
    "\n",
    "df_salary.position = ['Jnr_employee' if i == 1 else 'Manager' if  i == 2 \n",
    "                      else 'Executive' for i in df_salary.position]\n",
    "\n",
    "df_salary.Field = ['Engineering' if i == 1 else 'Finance' if i == 2\n",
    "                   else 'Human Resource' if i == 3 else 'Marketing' \n",
    "                   for i in df_salary.Field]    \n",
    "df_salary = pd.DataFrame(df_salary)\n",
    "df_salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into df_train train and test set\n",
    "\n",
    "df_train, df_test = train_test_split(df_salary, test_size=0.2, random_state=42)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartiles and IQR:df_train\n",
    "q75_train, q25_train = np.percentile(df_train['salary'], [75 ,25])\n",
    "iqr_train = q75_train - q25_train\n",
    "\n",
    "# Extremes' boundaries: df_train\n",
    "lower_bound = q25_train - iqr_train*1.5\n",
    "upper_bound = q75_train + iqr_train*1.5\n",
    "\n",
    "#Determining if an entry is an extreme or an outlier:df_train\n",
    "df_train['Is_it_an_extreme'] = ['Yes' if i < lower_bound else 'Yes' \n",
    "                                if i > upper_bound else \"No\" \n",
    "                                for i in df_train.salary]\n",
    "df_outliers = df_train[df_train.Is_it_an_extreme == 'Yes']\n",
    "\n",
    "#Dropping outliers\n",
    "df_train = df_train[df_train.Is_it_an_extreme != 'Yes']\n",
    "\n",
    "#df_train descriptive statistics\n",
    "# df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hot encoding Dummy variables for Field variable with Human Resource, Position with Executive and Gender with Females as references respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies =pd.get_dummies(df_train.Field).loc[:,['Engineering','Finance','Marketing']]\n",
    "df_dummies1 =pd.get_dummies(df_train.position).loc[:,['Jnr_employee','Manager']]\n",
    "df_dummies2 =pd.get_dummies(df_train.gender).loc[:,['male']]\n",
    "\n",
    "df_train = df_train.join(df_dummies)\n",
    "df_train = df_train.join(df_dummies1)\n",
    "df_train = df_train.join(df_dummies2)\n",
    "\n",
    "df_dummies3 =pd.get_dummies(df_test.Field).loc[:,['Engineering','Finance','Marketing']]\n",
    "df_dummies4 =pd.get_dummies(df_test.position).loc[:,['Jnr_employee','Manager']]\n",
    "df_dummies5 =pd.get_dummies(df_test.gender).loc[:,['male']]\n",
    "df_test = df_test.join(df_dummies3)\n",
    "df_test = df_test.join(df_dummies4)\n",
    "df_test = df_test.join(df_dummies5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. correlation matrix comparing the relationship of salary to the predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.corr(method='pearson').head(1)\n",
    "# df_train.corr(method='spearman')\n",
    "# df_train.corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train.drop('salary', axis=1).corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "sns.heatmap(df_train.drop('salary', axis=1).corr(method='kendall'),\n",
    "            annot=True, ax=ax, linewidths=0.1)\n",
    "plt.title('Correlation of featues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any multicollinearity or other problems that may be a problem in the multiple regression\n",
    "\n",
    "What the regression model is going to do is to disentangle the individual effects of years worked and years rank on salary. Given the opportunity that the regression model does tease apart these individual effects, such individual effects become obscured. Multicolinearity happens when the X variables are themselves related.\n",
    "\n",
    "This is a perfect description for multicolinearity, if **one year a experience is added**, the likelihood that one stays in that **rank for one more year** is close to 100%, similarly with **market value**, it is common knowledge that years of experience do actually increase the market value of an individual, so the regression model will have a very unrealistic way of analysing if the effect on salary was due to an increase in market value or due to one more year of experience or one more year of being in that particular rank. Therefore, drop years worked and years absent(the former because it is highly correlated with male but not with salary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model creation of salary prediction based on multivariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "# create a fitted model: salary vs Years worked _ Market + Years Rank\n",
    "variables = ['yearsworked' ,'market' ,'yearsrank','Engineering','Finance' ,'Marketing' ,'Jnr_employee', 'Manager']\n",
    "model= smf.ols(formula='salary ~ yearsworked + market + yearsrank+ Engineering + Finance + Marketing +Jnr_employee + Manager', data=df_train).fit()\n",
    "print(model.params)\n",
    "print(color.BOLD + \"This model has a higher R-squared (0.816) than the previous model's(0.708), This model provides a better fit to the data than a model that only one variable years worked\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1: predict salary using years worked\n",
    "df_train1 = model.predict(df_train)\n",
    "df_train1 = pd.DataFrame(df_train1)\n",
    "\n",
    "#Mapping 2 columns: Observed salary together with Predicted salary\n",
    "df_train1['Actual Salary'] = df_train['salary']\n",
    "df_train1= df_train1.rename(columns={0:'Predicted Salary'})\n",
    "df_train1['Actual Salary'] = df_train1['Actual Salary'].astype(float)\n",
    "df_train1['Predicted Salary'] = df_train1['Predicted Salary'].astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a residual column( a residual vertical distance between a data point and the regression line)\n",
    "df_train1['Residual'] = (df_train1['Actual Salary'] - df_train1['Predicted Salary'])\n",
    "\n",
    "#calculating the RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "y_actual1 = df_train1['Actual Salary']\n",
    "y_predicted1 = df_train1['Predicted Salary']\n",
    "rmse_train = rmse(df_train.salary, model.predict(df_train[variables]))\n",
    "rmse_test = rmse(df_test.salary, model.predict(df_test[variables]))\n",
    "# train_rmse = rmse(df_train.salary, model.predict(df_train[variables]))\n",
    "# test_rmse = rmse(df_test.salary, model.predict(df_test[variables]))\n",
    "#standardizing residuals\n",
    "#Standardized residual = (observed count – expected count) / √expected count\n",
    "df_train1['Standardised Residuals'] = df_train1.Residual/rmse_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(df_train1['Predicted Salary'],df_train1['Standardised Residuals'], lowess= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data points are pretty symmetrically distributed, tending to cluster towards the middle of the plot and  they’re clustered around y = 0 showing no patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Running the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartiles and IQR:df_test\n",
    "q75_test, q25_test = np.percentile(df_test['salary'], [75 ,25])\n",
    "iqr_test = q75_test - q25_test\n",
    "\n",
    "# Extremes' boundaries: df_test\n",
    "test_lower_bound = q25_test - iqr_test*1.5\n",
    "test_upper_bound = q75_test + iqr_test*1.5\n",
    "\n",
    "#Determining if an entry is an extreme or an outlier:df_test\n",
    "df_test['Is_it_an_extreme'] = ['Yes' if i < test_lower_bound else 'Yes'\n",
    "                               if i > test_upper_bound else \"No\"\n",
    "                               for i in df_test.salary]\n",
    "df_test_outliers = df_test[df_test.Is_it_an_extreme == 'Yes']\n",
    "\n",
    "#Dropping outliers\n",
    "df_test = df_test[df_test.Is_it_an_extreme != 'Yes']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1: predict salary using years worked\n",
    "model1= smf.ols(formula='salary ~ yearsworked + market + yearsrank+ Engineering + Finance + Marketing +Jnr_employee + Manager', data=df_test).fit()\n",
    "\n",
    "df_test1 = model1.predict(df_test)\n",
    "df_test1 = pd.DataFrame(df_test1)\n",
    "\n",
    "#Mapping 2 columns: Observed salary together with Predicted salary\n",
    "df_test1['Actual Salary'] = df_test['salary']\n",
    "df_test1= df_test1.rename(columns={0:'Predicted Salary'})\n",
    "df_test1['Actual Salary'] = df_test1['Actual Salary'].astype(float)\n",
    "df_test1['Predicted Salary'] = df_test1['Predicted Salary'].astype(float)\n",
    "\n",
    "#Creating a residual column( a residual vertical distance between a data point and the regression line)\n",
    "df_test1['Residual'] = (df_test1['Actual Salary'] - df_test1['Predicted Salary'])\n",
    "\n",
    "#standardizing residuals\n",
    "#Standardized residual = (observed count – expected count) / √expected count\n",
    "df_test1['Standardised Residuals'] = df_test1.Residual/rmse_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 RMSE Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The RMSE of the train data is: ',rmse_train)\n",
    "print('And The RMSE of the test data is: ',rmse_test,'which shows little evidence of underfitting nor underfitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "After such evidence, it is safe to conclude that this is a good model to predict salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
